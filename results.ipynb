{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline_knn_time': array([0.1540075, 0.0070467, 0.0059965]),\n",
       " 'baseline_knn_acc': array([0.62790698, 0.69767442, 0.58139535]),\n",
       " 'baseline_time': array([0.0013885, 0.0009983, 0.0085672, 0.0037015]),\n",
       " 'baseline_acc': array([0.58139535, 0.53488372, 0.6744186 , 0.72093023]),\n",
       " 'smart_time': array([[[2.3594546, 0.0590264],\n",
       "         [0.0597788, 0.0608105],\n",
       "         [0.0633466, 0.0617818]],\n",
       " \n",
       "        [[0.0539741, 0.0560436],\n",
       "         [0.0561274, 0.0598776],\n",
       "         [0.0579494, 0.0598743]],\n",
       " \n",
       "        [[0.0562593, 0.0647282],\n",
       "         [0.0617295, 0.0715498],\n",
       "         [0.0676939, 0.0727452]],\n",
       " \n",
       "        [[0.0645766, 0.0715691],\n",
       "         [0.0708678, 0.0721596],\n",
       "         [0.0748834, 0.0767115]]]),\n",
       " 'smart_acc': array([[[0.60465116, 0.6744186 ],\n",
       "         [0.69767442, 0.6744186 ],\n",
       "         [0.69767442, 0.69767442]],\n",
       " \n",
       "        [[0.60465116, 0.62790698],\n",
       "         [0.6744186 , 0.69767442],\n",
       "         [0.62790698, 0.65116279]],\n",
       " \n",
       "        [[0.62790698, 0.69767442],\n",
       "         [0.6744186 , 0.6744186 ],\n",
       "         [0.62790698, 0.65116279]],\n",
       " \n",
       "        [[0.62790698, 0.62790698],\n",
       "         [0.69767442, 0.6744186 ],\n",
       "         [0.62790698, 0.62790698]]]),\n",
       " 'ks': [3, 5, 7],\n",
       " 'tresholds': [0.6, 0.8]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "with open(os.path.join(\"results\", \"glass\", f'results_0.pickle'), 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2] [3 5 2]\n",
      "5 8.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_neighbors = np.array([0,1,2,0,1,2,0,1,1,1])\n",
    "k=len(y_neighbors)\n",
    "treshold = 0.8\n",
    "\n",
    "unique, counts = np.unique(y_neighbors, return_counts=True)\n",
    "dominant_class = unique[np.argmax(counts)]\n",
    "print(unique, counts)\n",
    "\n",
    "print(counts[np.argmax(counts)], treshold*k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from average_results import ret_avg_results\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "def generate_table_exp1(datasets=['mnist', 'covertype', 'yeast', 'skin', 'statlog'],knn_algo:Literal['brute', 'kd_tree', 'ball_tree']='brute'):\n",
    "    ret = ret_avg_results(datasets=datasets, knn_algo=knn_algo)\n",
    "    if ret is None:\n",
    "        print(\"No results found\")\n",
    "        return\n",
    "\n",
    "    baselines = {}\n",
    "    smart_accs = {}\n",
    "    for dataset in sorted(ret.keys()):\n",
    "        results_dict = ret[dataset]\n",
    "        clfs= results_dict[\"clfs\"]\n",
    "        ks= results_dict['ks']\n",
    "        thresholds= results_dict['thresholds']\n",
    "        t1_idx = thresholds.index(1.0)\n",
    "        # print(clfs)\n",
    "        # x_baselines = [\"{:.1f}\".format(xb * 100) for xb in results_dict[\"baseline_acc\"]]\n",
    "        # baselines[dataset] = x_baselines\n",
    "        # f.write(f'{dataset}, ks: {ks}\\n')\n",
    "        # f.write(\"\\t\".join(x_baselines))\n",
    "        # f.write('\\n')\n",
    "        \n",
    "        smart= results_dict[f\"smart_acc\"] #shape = (n_clfs, n_k, n_t)\n",
    "        smart = np.swapaxes(smart, 1, 2) # shape = (n_clfs, n_t, n_k)\n",
    "        for iclf, clf in enumerate(clfs):\n",
    "            baselines[f'{dataset}_{clf}'] = \"{:.1f}\".format(results_dict[\"baseline_acc\"][iclf] * 100)\n",
    "\n",
    "            curr_smart = smart[iclf,t1_idx,:] # shape = (n_k)\n",
    "            k_le_10 = [idx for idx, k in enumerate(ks) if k==10]\n",
    "            mean_acc_k_le_10 = np.mean(curr_smart[k_le_10])\n",
    "            means = [mean_acc_k_le_10] + [np.mean(curr_smart[idx]) for idx in range(len(ks)) if ks[idx] > 10]\n",
    "            means = [\"{:.1f}\".format(mean * 100) for mean in means]\n",
    "            # print(f'{dataset}_{clf}')\n",
    "            # print(means)\n",
    "\n",
    "            smart_accs[f\"{dataset}_{clf}\"] = means\n",
    "    with open('exp1_tab.txt','w') as f:\n",
    "        # for dataset, clf in product(datasets, clfs):\n",
    "        finals = {}\n",
    "        for dataset in sorted(datasets):\n",
    "            for clf in sorted(clfs):\n",
    "                # f.write(f'{dataset}_{clf}\\n')\n",
    "                baseline = baselines[f'{dataset}_{clf}']\n",
    "                smarts = smart_accs[f'{dataset}_{clf}']\n",
    "\n",
    "                final = np.array(smarts + [baseline], dtype=object).reshape((2,3))\n",
    "                finals[f'{dataset}_{clf}'] = final\n",
    "\n",
    "        finals_per_ds = []\n",
    "        for dataset in sorted(datasets):\n",
    "            final_ds = np.hstack([finals[f'{dataset}_{clf}'] for clf in sorted(clfs)])\n",
    "            finals_per_ds.append(final_ds)\n",
    "\n",
    "        final_arr = np.vstack(finals_per_ds)\n",
    "        final_arr = final_arr.tolist()\n",
    "        # print(final_arr)\n",
    "        f.write(\"\\n\".join([\"\\t\".join(row) for row in final_arr]))\n",
    "        # print(final_arr)\n",
    "        # np.savetxt(\"exp1_tab.txt\", final_arr, delimiter=\"\\t\")\n",
    "        # print(final_arr.shape)\n",
    "            # print(final_ds.shape)\n",
    "\n",
    "            #     f.write(\"\\t\".join(means))\n",
    "            #     f.write(\"\\t\")\n",
    "            # f.write('\\n')\n",
    "                \n",
    "def generate_table_exp2(datasets=['mnist', 'covertype', 'yeast', 'skin', 'statlog'],knn_algo:Literal['brute', 'kd_tree', 'ball_tree']='brute'):\n",
    "    ret = ret_avg_results(datasets=datasets, knn_algo=knn_algo)\n",
    "    if ret is None:\n",
    "        print(\"No results found\")\n",
    "        return\n",
    "\n",
    "    baseline_accs = {}\n",
    "    baseline_times = {}\n",
    "    smart_accs = {}\n",
    "    smart_times = {}\n",
    "    for dataset in sorted(ret.keys()):\n",
    "        results_dict = ret[dataset]\n",
    "        clfs= results_dict[\"clfs\"]\n",
    "        ks= results_dict['ks']\n",
    "        thresholds= results_dict['thresholds']\n",
    "        # t1_idx = thresholds.index(1.0)\n",
    "        # t_p6_idx = thresholds.index(0.6)\n",
    "        \n",
    "        smart_acc= results_dict[f\"smart_acc\"] #shape = (n_clfs, n_k, n_t)\n",
    "        smart_acc = np.swapaxes(smart_acc, 1, 2) # shape = (n_clfs, n_t, n_k)\n",
    "        smart_time = results_dict[f\"smart_time\"] #shape = (n_clfs, n_k, n_t)\n",
    "        smart_time = np.swapaxes(smart_time, 1, 2)\n",
    "        \n",
    "        for iclf, clf in enumerate(clfs):\n",
    "            baseline_accs[f'{dataset}_{clf}'] = \"{:.1f}\".format(results_dict[\"baseline_acc\"][iclf] * 100)\n",
    "            baseline_times[f'{dataset}_{clf}'] = \"{:.1f}\".format(results_dict[\"baseline_time\"][iclf])\n",
    "\n",
    "            for it, t in enumerate(filter(lambda t: t in (0.6,1.0), thresholds)):\n",
    "                \n",
    "\n",
    "                curr_smart = smart_acc[iclf,it,:] # shape = (n_k)\n",
    "                curr_time = smart_time[iclf,it,:] # shape = (n_k)\n",
    "\n",
    "                best_k = min(filter(lambda k: ks.index(k) in np.argwhere(curr_smart == np.amax(curr_smart)),ks))\n",
    "                best_k_idx = ks.index(best_k)\n",
    "                best_k_acc = curr_smart[best_k_idx]\n",
    "                best_k_acc = \"{:.1f}\".format(best_k_acc * 100)\n",
    "                best_k_time = curr_time[best_k_idx]\n",
    "                best_k_time = \"{:.1f}\".format(best_k_time)\n",
    "\n",
    "                smart_accs[f\"{dataset}_{clf}_{t}\"] = best_k_acc\n",
    "                smart_times[f\"{dataset}_{clf}_{t}\"] = best_k_time\n",
    "                # if best_k < 10:\n",
    "                    # print(f'{dataset}_{clf} t:{t} best k: {best_k} acc: {best_k_acc}')\n",
    "            # print()\n",
    "        # print()\n",
    "    with open('exp2_tab.txt','w') as f:\n",
    "        finals = {}\n",
    "        for dataset in sorted(datasets):\n",
    "            for clf in sorted(clfs):\n",
    "                baseline_acc = baseline_accs[f'{dataset}_{clf}']\n",
    "                baseline_time = baseline_times[f'{dataset}_{clf}']\n",
    "                smart_accs_final = [smart_accs[f'{dataset}_{clf}_{t}'] for t in (0.6, 1)]\n",
    "                smart_times_final = [smart_times[f'{dataset}_{clf}_{t}'] for t in (0.6, 1)]\n",
    "\n",
    "                final = np.array(smart_accs_final + [baseline_acc] + smart_times_final +  [baseline_time], dtype=object).reshape((2,3))\n",
    "                finals[f'{dataset}_{clf}'] = final\n",
    "\n",
    "        finals_per_ds = []\n",
    "        for dataset in sorted(datasets):\n",
    "            final_ds = np.hstack([finals[f'{dataset}_{clf}'] for clf in sorted(clfs)])\n",
    "            finals_per_ds.append(final_ds)\n",
    "\n",
    "        final_arr = np.vstack(finals_per_ds)\n",
    "        final_arr = final_arr.tolist()\n",
    "        f.write(\"\\n\".join([\"\\t\".join(row) for row in final_arr]))    \n",
    "        \n",
    "\n",
    "generate_table_exp1(datasets=['covertype', 'glass', 'mnist', 'skin','statlog', 'usps', 'wine', 'yeast'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
